{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zm0ut1wpx-ll",
        "outputId": "9a317de8-68c5-4687-8eb9-033abe384a9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features Preview:\n",
            "    sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
            "0                5.1               3.5                1.4               0.2\n",
            "1                4.9               3.0                1.4               0.2\n",
            "2                4.7               3.2                1.3               0.2\n",
            "3                4.6               3.1                1.5               0.2\n",
            "4                5.0               3.6                1.4               0.2\n",
            "\n",
            "Target Preview:\n",
            " 0    0\n",
            "1    0\n",
            "2    0\n",
            "3    0\n",
            "4    0\n",
            "Name: species, dtype: int64\n",
            "\n",
            "Missing Values:\n",
            " sepal length (cm)    0\n",
            "sepal width (cm)     0\n",
            "petal length (cm)    0\n",
            "petal width (cm)     0\n",
            "dtype: int64\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "      setosa       1.00      1.00      1.00        10\n",
            "  versicolor       1.00      1.00      1.00         9\n",
            "   virginica       1.00      1.00      1.00        11\n",
            "\n",
            "    accuracy                           1.00        30\n",
            "   macro avg       1.00      1.00      1.00        30\n",
            "weighted avg       1.00      1.00      1.00        30\n",
            "\n",
            "Accuracy: 1.0\n",
            "Precision (macro): 1.0\n",
            "Recall (macro): 1.0\n"
          ]
        }
      ],
      "source": [
        "# iris_classifier.ipynb\n",
        "\n",
        "# üìå Import required libraries\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report\n",
        "\n",
        "# üìä Load Iris dataset\n",
        "iris = load_iris()\n",
        "X = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
        "y = pd.Series(iris.target, name=\"species\")\n",
        "\n",
        "# üëÅÔ∏è Preview the data\n",
        "print(\"Features Preview:\\n\", X.head())\n",
        "print(\"\\nTarget Preview:\\n\", y.head())\n",
        "\n",
        "# ‚öôÔ∏è Check for missing values\n",
        "print(\"\\nMissing Values:\\n\", X.isnull().sum())\n",
        "\n",
        "# üß™ Split data into train and test sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# üå≥ Initialize and train Decision Tree Classifier\n",
        "clf = DecisionTreeClassifier(random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# üîÆ Make predictions\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# ‚úÖ Evaluate the model\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred, target_names=iris.target_names))\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Precision (macro):\", precision_score(y_test, y_pred, average='macro'))\n",
        "print(\"Recall (macro):\", recall_score(y_test, y_pred, average='macro'))\n"
      ]
    }
  ]
}